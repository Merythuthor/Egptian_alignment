
import re


PROTECT_RE = re.compile(r'\[[^\]]*\]|<[^>]*>')

def _process_with_protection(text: str, processor) -> str:

    out = []
    last = 0

    def process_plain(seg: str) -> str:
        if not seg:
            return seg
        parts = []

        for m in re.finditer(r'\s+|[^\s]+', seg):
            tok = m.group(0)
            if tok.isspace():
                parts.append(tok)
            else:
                parts.append(processor(tok))
        return ''.join(parts)

    for m in PROTECT_RE.finditer(text):
        if m.start() > last:
            out.append(process_plain(text[last:m.start()]))
        out.append(m.group(0))
        last = m.end()

    if last < len(text):
        out.append(process_plain(text[last:]))

    return ''.join(out)



EGYPTIAN_TO_LATIN_MAP = {

        'w': 'u',
        'Å¡': 'sh',
        'z': 's',
        'Å›': 's',
        'á¸': 'dz',
        'á¸¥': 'h',
        'á¸«': 'kh',
        'hÌ±': 'kh',
        'áº–': 'kh',
        'á¹¯': 'tz',
        'á¹±': 'tj',
        'iÌ¯': 'j',
        'êž½': 'j',
        'êœ¥': 'a',
        'êœ£': 'qa',
        'á¼°': 'j',
        'á¼±': 'j',
        'â¸—': '',
        '=': '',
}


COPTIC_TO_LATIN_MAP = {

        'â²Ÿâ²©': 'ou',
        'Ï¯': 'tj',
        'Î¦': 'ph',
        'Î±': 'a',
        'Î²': 'b',
        'Î³': 'u',
        'Î´': 'd',
        'Îµ': 'e',
        'Î¶': 'z',
        'Î¸': 'th',
        'Î¹': 'j',
        'Îº': 'k',
        'Î»': 'l',
        'Î¼': 'm',
        'Î½': 'n',
        'Î¾': 'ks',
        'Î¿': 'o',
        'Ï€': 'p',
        'Ï': 'r',
        'Ï‚': 's',
        'Ïƒ': 's',
        'Ï„': 't',
        'Ï…': 'u',
        'Ï†': 'ph',
        'Ï‡': 'kh',
        'Ï‰': 'oo',
        'ÏŒ': 'o',
        'Ï£': 'sh',
        'Ï¥': 'f',
        'Ï§': 'kh',
        'Ï©': 'h',
        'Ï«': 'dz',
        'Ï­': 'g',

        'â€ ': 'tj',
        'â²': 'a',
        'â²ƒ': 'b',
        'â²…': 'g',
        'â²‡': 'd',
        'â²ˆ': 'e',
        'â²‰': 'e',
        'â²‹': '6',
        'â²': 'z',
        'â²': 'ee',
        'â²‘': 'th',
        'â²“': 'j',
        'â²•': 'k',
        'â²—': 'l',
        'â²™': 'm',
        'â²›': 'n',
        'â²': 'ks',
        'â²Ÿ': 'o',
        'â²¡': 'p',
        'â²£': 'r',
        'â²¥': 's',
        'â²§': 't',
        'â²©': 'u',
        'â²«': 'ph',
        'â²­': 'kh',
        'â²¯': 'ps',
        'â²±': 'oo',

}


def _augment_case_variants_for_map(d: dict):
    add = {}
    for k, v in list(d.items()):

        variants = {k.upper(), k[:1].upper() + k[1:]}
        for var in variants:
            if var != k and var not in d:
                add[var] = v
    d.update(add)

_augment_case_variants_for_map(COPTIC_TO_LATIN_MAP)

def normalize_to_latin(text: str, lang: str) -> str:

    def _proc(seg: str) -> str:
        mapping_dict = None
        if lang in ["hieroglyphic", "demotic"]:
            mapping_dict = EGYPTIAN_TO_LATIN_MAP
        elif lang in ["bohairic", "sahidic"]:
            mapping_dict = COPTIC_TO_LATIN_MAP

        if mapping_dict:

            sorted_keys = sorted(mapping_dict.keys(), key=len, reverse=True)

            normalized_text = seg
            for key in sorted_keys:
                normalized_text = normalized_text.replace(key, mapping_dict[key])
        else:

            normalized_text = seg


        normalized_text = normalized_text.replace('.', '')



        return " ".join(normalized_text.split())


    return _process_with_protection(text, _proc)




EGYPTIAN_TO_IPA_MAP = {
    'êœ£': 'Ê”',  # Aleph -> Glottal stop
    'êœ¥': 'Ê•',  # Ayin -> Voiced pharyngeal fricative
    'y': 'j',
    'iÌ¯': 'j',
    'êž½': 'j',
    'á¼°': 'j',
    'á¼±': 'j',
    'w': 'u',
    'b': 'b',
    'p': 'p',
    'f': 'f',
    'm': 'm',
    'n': 'n',
    'r': 'r',
    'h': 'h',
    'á¸¥': 'Ä§',
    'á¸«': 'Ï‡',
    'áº–': 'Ã§',
    's': 's',
    'z': 's',
    'Å¡': 'Êƒ',
    'q': 'q',
    'k': 'k',
    'g': 'g',
    't': 't',
    'á¹¯': 'tÊƒ',
    'd': 'd',
    'á¸': 'ÉŸ',
    'â¸—': '',
    '=': '',
}


COPTIC_TO_IPA_RULES = [

    (re.compile('â²Ÿâ²©'), 'u'),
    (re.compile('â²‰â²“'), 'i'),
    (re.compile('â²'), 'ks'),
    (re.compile('â²¯'), 'ps'),
    (re.compile('Ï¯'), 'ti'),
    (re.compile('â²­'), 'kÊ°'),
    (re.compile('â²‘'), 'tÊ°'),
    (re.compile('â²«'), 'pÊ°'),
    (re.compile('Ï£'), 'Êƒ'),
    (re.compile('Ï¥'), 'f'),
    (re.compile('Ï§'), 'x'),
    (re.compile('Ï©'), 'h'),
    (re.compile('Ï«'), 'ÉŸ'),
    (re.compile('Ï­'), 'tÊƒ'),

    (re.compile('â²'), 'a'),
    (re.compile('â²ƒ'), 'b'),
    (re.compile('â²…'), 'g'),
    (re.compile('â²‡'), 'd'),
    (re.compile('â²‰'), 'É™'),
    (re.compile('â²'), 'z'),
    (re.compile('â²'), 'eË'),
    (re.compile('â²“'), 'i'),
    (re.compile('â²•'), 'k'),
    (re.compile('â²—'), 'l'),
    (re.compile('â²™'), 'm'),
    (re.compile('â²›'), 'n'),
    (re.compile('â²Ÿ'), 'o'),
    (re.compile('â²¡'), 'p'),
    (re.compile('â²£'), 'r'),
    (re.compile('â²¥'), 's'),
    (re.compile('â²§'), 't'),
    (re.compile('â²©'), 'u'),
    (re.compile('â²±'), 'oË'),
]


def _make_rules_ignore_case(rules):
    new = []
    for pat, rep in rules:

        if pat.flags & re.IGNORECASE:
            new.append((pat, rep))
        else:
            new.append((re.compile(pat.pattern, pat.flags | re.IGNORECASE), rep))
    return new

COPTIC_TO_IPA_RULES = _make_rules_ignore_case(COPTIC_TO_IPA_RULES)


def _egyptian_insert_schwa(ipa_text: str) -> str:
    words = ipa_text.split()
    if not words:
        return ipa_text

    LONG_TOKENS = ['tÊƒ', 'dÊ’']

    symbols_in_text = {ch for ch in ipa_text if ch.strip()}
    for v in EGYPTIAN_TO_IPA_MAP.values():
        symbols_in_text.update(list(v))


    PUNCTS = {'.'}

    symbols_in_text -= PUNCTS
    SINGLE_TOKENS = sorted({c for c in symbols_in_text if len(c) == 1})

    tok_pattern = re.compile(
        r'(?:' + '|'.join(map(re.escape, LONG_TOKENS)) +
        r'|[' + ''.join(map(re.escape, SINGLE_TOKENS)) + r'])'
    )

    BLOCKERS = {'j', 'Ê”', 'Ê•', 'w', 'a', 'e', 'i', 'o', 'u', 'É™'}

    out_words = []
    for w in words:

        w_clean = w.replace('.', '')

        # â˜… æ–°ï¼šæŒ‰è¿žå­—ç¬¦åˆ‡åˆ†å¹¶ä¿ç•™åˆ†éš”ç¬¦æœ¬èº«
        parts = re.split(r'(-)', w_clean)

        seg_outs = []
        for part in parts:
            if part == '-':
                seg_outs.append(part)
                continue

            seg = part
            tokens = tok_pattern.findall(seg)
            if not tokens:
                seg_outs.append(seg)
                continue

            if len(tokens) == 1:

                if tokens[0] in BLOCKERS:
                    seg_outs.append(tokens[0])
                else:
                    seg_outs.append('e' + tokens[0])
                continue

            new_seq = [tokens[0]]
            for i in range(len(tokens) - 1):
                left, right = tokens[i], tokens[i + 1]
                if left in BLOCKERS or right in BLOCKERS:
                    pass
                else:
                    new_seq.append('e')
                new_seq.append(right)
            seg_outs.append(''.join(new_seq))

        out_words.append(''.join(seg_outs))

    return ' '.join(out_words)


import re, unicodedata

def _sub_by_map(text: str, mapping: dict, norm: str = "NFC") -> str:

    if norm:
        text = unicodedata.normalize(norm, text)
        mapping = {unicodedata.normalize(norm, k): v for k, v in mapping.items()}

    if not mapping:
        return text

    pattern = re.compile("|".join(sorted(map(re.escape, mapping.keys()), key=len, reverse=True)))
    return pattern.sub(lambda m: mapping[m.group(0)], text)

def normalize_to_ipa(text: str, lang: str) -> str:

    def _proc(seg: str) -> str:
        if lang in ["hieroglyphic", "demotic"]:
            normalized_text = _sub_by_map(seg, EGYPTIAN_TO_IPA_MAP, norm="NFC")
            normalized_text = _egyptian_insert_schwa(normalized_text)
        elif lang in ["bohairic", "sahidic"]:
            normalized_text = seg
            for pattern, replacement in COPTIC_TO_IPA_RULES:
                normalized_text = pattern.sub(replacement, normalized_text)
        else:
            normalized_text = seg

        normalized_text = normalized_text.replace('.', '')

        return " ".join(normalized_text.split())

    return _process_with_protection(text, _proc)




def normalize_text(text: str, lang: str, mode: str) -> str:
    if mode.upper() == "LATIN":
        return normalize_to_latin(text, lang)
    elif mode.upper() == "IPA":
        return normalize_to_ipa(text, lang)
    elif mode.upper() == "NONE" or mode is None:
        return text
    else:
        raise ValueError(f"Unknown normalization mode: {mode}")


if __name__ == "__main__":


    test_cases = [

        ("sÅ¡ nfr.t m áº–r.w â¸—f", "hieroglyphic"),
        ("pêœ£-dy-wsêž½r-m-jwn", "demotic"),
        ("Å¡êœ¥-á¸.t", "demotic"),


        ("â²›â²Ÿâ²©Ï¥â²‰", "bohairic"),
        ("Ï£â²â²“", "sahidic"),
        ("Ï©â²Ÿâ²£â²“", "bohairic"),
        ("Ï«â²“Ï«", "sahidic"),


        ("This is a beautiful test.", "english")
    ]

    print("\n" + "=" * 80)
    print("ðŸš€ STARTING NORMALIZATION TEST ðŸš€")
    print("=" * 80)

    for original_text, lang in test_cases:
        print(f"\n--- Testing Case ---")
        print(f"Original Text: '{original_text}' ({lang})")


        latin_normalized = normalize_text(original_text, lang, "LATIN")
        print(f"  -> LATIN Mode: '{latin_normalized}'")


        ipa_normalized = normalize_text(original_text, lang, "IPA")
        print(f"  -> IPA Mode  : '{ipa_normalized}'")

    print("\n" + "=" * 80)
    print("âœ… TEST COMPLETE âœ…")
    print("=" * 80)

    print("\n=== IPA Demo (fill your xxx strings) ===")

    samples = {
        "hieroglyphic": "<hiero> [gap] pêœ£y-dy.t-êœ£s.t [gap] [gap] [gap]",
        "demotic": "n-á¸r.t nêœ£-wêœ£á¸¥-êž½b-rêœ¥ á¸¥wy â¸—y r-bnr-r nêœ£ êœ¥.wy.w nêœ£y â¸—y êž½t.á¹±.w r-á¸bêœ£ msty â¸—y",
        "sahidic": "â²ªâ²› Ï£â²Ï«â²‰ â²™ â²¡â²â²“ â²‰â²§ Ï«â²± â²› â²›â²â²“ Ï©â²‰â²› Ï­â²Ÿâ²— â²›â²‰",
        "bohairic": "â²§â²Ÿâ²§â²‰ â²‰Ï¥â²‰ â²Ÿâ²©â²±â²§â²‰â²ƒ â²›Ï«â²‰ â²¡â²“ â²¡â²›â²‰â²©â²™â² â²Ÿâ²©â²ŸÏ© â²‰Ï¥â²‰ â²¥â²“â²›â²“ â²Ÿâ²©â²ŸÏ© â²‰Ï¥â²‰ â²­â²± â²‰â²ƒâ²Ÿâ²— â²‘â²â²“ â²¡â²‰ Ï¯ Ï«â²Ÿâ²™ â²›â²§â²‰ â²¡â² â²›â²Ÿâ²©Ï¯",

    }

    for lg, raw in samples.items():
        ipa = normalize_text(raw, lg, "IPA")
        print(f"[{lg}]  raw: {raw}  ->  IPA: {ipa}")

    for raw in ["nfr", "mnys", "mnyst", "my","mny", "êž½n", "pêœ£-dy-wsêž½r"]:
        print(f"[hieroglyphic] {raw} -> {normalize_text(raw, 'hieroglyphic', 'IPA')}")

    print("\n=== LATIN Demo (fill your xxx strings) ===")

    samples = {
        "hieroglyphic": "<hiero> [gap] pêœ£y-dy.t-êœ£s.t [gap] [gap] [gap]",
        "demotic": "n-á¸r.t nêœ£-wêœ£á¸¥-êž½b-rêœ¥ á¸¥wy â¸—y r-bnr-r nêœ£ êœ¥.wy.w nêœ£y â¸—y êž½t.á¹±.w r-á¸bêœ£ msty â¸—y",
        "sahidic": "â²ªâ²› Ï£â²Ï«â²‰ â²™ â²¡â²â²“ â²‰â²§ Ï«â²± â²› â²›â²â²“ Ï©â²‰â²› Ï­â²Ÿâ²— â²›â²‰",
        "bohairic": "â²§â²Ÿâ²§â²‰ â²‰Ï¥â²‰ â²Ÿâ²©â²±â²§â²‰â²ƒ â²›Ï«â²‰ â²¡â²“ â²¡â²›â²‰â²©â²™â² â²Ÿâ²©â²ŸÏ© â²‰Ï¥â²‰ â²¥â²“â²›â²“ â²Ÿâ²©â²ŸÏ© â²‰Ï¥â²‰ â²­â²± â²‰â²ƒâ²Ÿâ²— â²‘â²â²“ â²¡â²‰ Ï¯ Ï«â²Ÿâ²™ â²›â²§â²‰ â²¡â² â²›â²Ÿâ²©Ï¯",

    }

    for lg, raw in samples.items():
        latin = normalize_text(raw, lg, "LATIN")
        print(f"[{lg}]  raw: {raw}  ->  LATIN: {latin}")


    for raw in ["nfr", "mnys", "mnyst", "my", "mny", "êž½n", "pêœ£-dy-wsêž½r"]:
        print(f"[hieroglyphic] {raw} -> {normalize_text(raw, 'hieroglyphic', 'LATIN')}")
